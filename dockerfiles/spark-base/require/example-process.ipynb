{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = '/usr/local/spark'\n",
    "os.environ['IPYTHON']= '1'\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/conda/bin/python3.7'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']= 'ipython3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= 'notebook'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /home/jovyan/spark-streaming-kafka-0-8-assembly_2.11-2.4.5.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkContext\n",
    "from collections import OrderedDict\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from schema_registry.client import SchemaRegistryClient\n",
    "from schema_registry.serializers import MessageSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Singleton:\n",
    "\n",
    "    def _init_(self, cls):\n",
    "        self._cls = cls\n",
    "\n",
    "    def Instance(self):\n",
    "        try:\n",
    "            return self._instance\n",
    "        except AttributeError:\n",
    "            self._instance = self._cls()\n",
    "            return self._instance\n",
    "\n",
    "    def _call_(self):\n",
    "        raise TypeError('Singletons must be accessed through `Instance()`.')\n",
    "\n",
    "    def _instancecheck_(self, inst):\n",
    "        return isinstance(inst, self._cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaDecoder(object):\n",
    "    HOST = os.environ['SCHEMA_REGISTRY_URL']\n",
    "    SERIALIZER = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def initialize():\n",
    "        client = SchemaRegistryClient(SchemaDecoder.HOST)\n",
    "        SchemaDecoder.SERIALIZER = MessageSerializer(client)\n",
    "        return SchemaDecoder\n",
    "        \n",
    "    def deserialize(s):\n",
    "        decoded_message = SchemaDecoder.SERIALIZER.decode_message(s)\n",
    "        return decoded_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendRecord(partition):\n",
    "    global snort_label, snort_ts\n",
    "    client = MongoClient(URI) \n",
    "    mydb = client[\"bigdata\"]\n",
    "    \n",
    "    netDB = mydb[\"netflowmeter\"]\n",
    "    snortDB = mydb[\"snorqtt\"]\n",
    "    joinDB = mydb[\"ns_relation\"]\n",
    "    \n",
    "    for line in partition:\n",
    "        if line[0] == \"netflowmeter\":\n",
    "            netDB.insert_one(line[1])\n",
    "        elif line[0] == \"snorqtt\":\n",
    "            snort_ts = line[1].get('timestamp')\n",
    "            snort_label = line[1].get('alert_msg')\n",
    "            snortDB.insert_one(line[1])\n",
    "            \n",
    "    if(snort_ts is not None):\n",
    "        netDatas = netDB.find({'timestamp': snort_ts})\n",
    "        for data in netDatas:\n",
    "            print(data)\n",
    "            data.label = snort_label\n",
    "            joinDB.insert_one(data)\n",
    "            \n",
    "        snort_label = None\n",
    "        snort_ts = None\n",
    "    \n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"mongodb://172.31.0.3:27017\"\n",
    "decoder = SchemaDecoder.initialize()\n",
    "snort_label = None\n",
    "snort_ts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"SparkTAPySpark\")\n",
    "ssc = StreamingContext(sc, 30)\n",
    "topic = [\"netflowmeter\", \"snorqtt\"]\n",
    "brokers = os.environ['BROKER_SERVER']\n",
    "kafkaParams = dict({\"metadata.broker.list\":brokers})\n",
    "kafkaStream = KafkaUtils.createDirectStream (\n",
    "    ssc, \n",
    "    topic, \n",
    "    kafkaParams, \n",
    "    valueDecoder=decoder.deserialize,\n",
    "    messageHandler=(lambda msg : (msg.topic, msg.message))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafkaStream.foreachRDD(lambda rdd : rdd.foreachPartition(sendRecord))\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}